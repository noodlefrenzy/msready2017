{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hot Dog vs. Not Hot Dog\n",
    "## Cognitive Toolkit Edition\n",
    "\n",
    "We use the Transfer Learning example from the CNTK repository as our baseline, and build a model based on ResNet18 that can distinguish between hotdogs and various forms of Not hotdogs (See [this clip](https://www.youtube.com/watch?v=ACmydtFDTGs&feature=youtu.be) for reference). \n",
    "\n",
    "We'll start off with a few of the imports required for CNTK..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cntk as C\n",
    "import os\n",
    "from PIL import Image\n",
    "from cntk.device import try_set_default_device, gpu\n",
    "from cntk import load_model, placeholder, Constant, Trainer, UnitType\n",
    "from cntk.logging.graph import find_by_name, get_node_outputs\n",
    "from cntk.io import MinibatchSource, ImageDeserializer, StreamDefs, StreamDef\n",
    "import cntk.io.transforms as xforms\n",
    "from cntk.layers import Dense\n",
    "from cntk.learners import momentum_sgd, learning_rate_schedule, momentum_schedule\n",
    "from cntk.ops import combine, softmax\n",
    "from cntk.ops.functions import CloneMethod\n",
    "from cntk.losses import cross_entropy_with_softmax\n",
    "from cntk.metrics import classification_error\n",
    "from cntk.logging import log_number_of_parameters, ProgressPrinter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "Now we set up a few constants - where to find the base model we'll be using (you should have downloaded this before-hand using `download_model.py`), which layer from it to use, what you want the new layers to be named.\n",
    "\n",
    "We also set up our learning parameters\n",
    "- `max_epochs`: How many times do we want to run through our training data?\n",
    "- `mb_size`: We process multiple images at a time in a \"mini-batch\" - how many?\n",
    "- `lr_per_mb`: The _learning rate_ controls how quickly we converge vs. how much we jump around the \"search space\". Decaying it over time ensures (usually) that we gradually come to rest on an answer.\n",
    "- `momentum_per_mb`: Momentum ensures that when we're being told repeatedly that the answer is in a given \"direction\", we move more strongly in that direction.\n",
    "- `l2_reg_weight`: Regularization helps to ensure that models don't _overfit_ and just get good at predicting our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: C:\\dev\\git_ws\\msready2017\n"
     ]
    }
   ],
   "source": [
    "# general settings\n",
    "base_folder = os.getcwd()\n",
    "print('Current directory: {}'.format(base_folder))\n",
    "tl_model_file = os.path.join(base_folder, \"Output\", \"TransferLearning.model\")\n",
    "output_file = os.path.join(base_folder, \"Output\", \"predOutput.txt\")\n",
    "features_stream_name = 'features'\n",
    "label_stream_name = 'labels'\n",
    "new_output_node_name = \"prediction\"\n",
    "\n",
    "# Learning parameters\n",
    "max_epochs = 20\n",
    "mb_size = 50\n",
    "lr_per_mb = [0.2]*10 + [0.1]\n",
    "momentum_per_mb = 0.9\n",
    "l2_reg_weight = 0.0005\n",
    "\n",
    "# define base model location and characteristics\n",
    "_base_model_file = os.path.join(base_folder, \"ResNet_18.model\")\n",
    "_feature_node_name = \"features\"\n",
    "_last_hidden_node_name = \"z.x\"\n",
    "_image_height = 224\n",
    "_image_width = 224\n",
    "_num_channels = 3\n",
    "\n",
    "# define data location and characteristics\n",
    "_data_folder = os.path.join(base_folder, \"images\")\n",
    "_train_map_file = os.path.join(_data_folder, \"train.tsv\")\n",
    "_test_map_file = os.path.join(_data_folder, \"test.tsv\")\n",
    "_num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Model and the Data\n",
    "\n",
    "You noticed above that we're using \"mini-batches\" for our data, so we need to create a \"source\" for these mini-batches to come from. We do so by using the `ImageDeserializer` to read in our training data map-file (containing tab-delimited image file paths and labels, one per line). This splits the data into \"labels\" and \"features\", where the features are the raw image data and the labels are either \"hotdog\" (1) or \"not hotdog\" (0).\n",
    "\n",
    "For creating the model, we load in our downloaded pre-trained ResNet18 model. We then find the last \"feature layer\" (where it's learned all of the high-level features like \"cat's eye\" and \"dog's ear\"), clone the model from that point to the root, and add our own final predictor layer to tell us whether we have a hotdog or a \"not hotdog\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a minibatch source for training or testing\n",
    "def create_mb_source(map_file, image_width, image_height, num_channels, num_classes, randomize=True):\n",
    "    transforms = [xforms.scale(width=image_width, height=image_height, channels=num_channels, interpolations='linear')] \n",
    "    return MinibatchSource(ImageDeserializer(map_file, StreamDefs(\n",
    "            features =StreamDef(field='image', transforms=transforms),\n",
    "            labels   =StreamDef(field='label', shape=num_classes))),\n",
    "            randomize=randomize)\n",
    "\n",
    "\n",
    "# Creates the network model for transfer learning\n",
    "def create_model(base_model_file, feature_node_name, last_hidden_node_name, num_classes, input_features, freeze=False):\n",
    "    # Load the pretrained classification net and find nodes\n",
    "    base_model   = load_model(base_model_file)\n",
    "    feature_node = find_by_name(base_model, feature_node_name)\n",
    "    last_node    = find_by_name(base_model, last_hidden_node_name)\n",
    "\n",
    "    # Clone the desired layers with fixed weights\n",
    "    cloned_layers = combine([last_node.owner]).clone(\n",
    "        CloneMethod.freeze if freeze else CloneMethod.clone,\n",
    "        {feature_node: placeholder(name='features')})\n",
    "\n",
    "    # Add new dense layer for class prediction\n",
    "    feat_norm  = input_features - Constant(114)\n",
    "    cloned_out = cloned_layers(feat_norm)\n",
    "    z          = Dense(num_classes, activation=None, name=new_output_node_name) (cloned_out)\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "\n",
    "Training the model is where we put all of this together - we create our training mini-batch source, create our model, define how we want it to be judged, and set it off training. This code is fairly vanilla CNTK code, so I won't talk through it in detail. The important pieces to notice are the `Trainer` class, which takes in the model, the _criterion_ for judgment (loss function, evaluation metric), and the \"learner\". In our case we're using Stochastic Gradient Descent (SGD) with Momentum - a relatively standard method recently replaced in many cases with ADAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trains a transfer learning model\n",
    "def train_model(base_model_file, feature_node_name, last_hidden_node_name,\n",
    "                image_width, image_height, num_channels, num_classes, train_map_file,\n",
    "                num_epochs, max_images=-1, freeze=False):\n",
    "    epoch_size = sum(1 for line in open(train_map_file))\n",
    "    if max_images > 0:\n",
    "        epoch_size = min(epoch_size, max_images)\n",
    "\n",
    "    # Create the minibatch source and input variables\n",
    "    minibatch_source = create_mb_source(train_map_file, image_width, image_height, num_channels, num_classes)\n",
    "    image_input = C.input_variable((num_channels, image_height, image_width))\n",
    "    label_input = C.input_variable(num_classes)\n",
    "\n",
    "    # Define mapping from reader streams to network inputs\n",
    "    input_map = {\n",
    "        image_input: minibatch_source[features_stream_name],\n",
    "        label_input: minibatch_source[label_stream_name]\n",
    "    }\n",
    "\n",
    "    # Instantiate the transfer learning model and loss function\n",
    "    tl_model = create_model(base_model_file, feature_node_name, last_hidden_node_name, num_classes, image_input, freeze)\n",
    "    ce = cross_entropy_with_softmax(tl_model, label_input)\n",
    "    pe = classification_error(tl_model, label_input)\n",
    "\n",
    "    # Instantiate the trainer object\n",
    "    lr_schedule = learning_rate_schedule(lr_per_mb, unit=UnitType.minibatch)\n",
    "    mm_schedule = momentum_schedule(momentum_per_mb)\n",
    "    learner = momentum_sgd(tl_model.parameters, lr_schedule, mm_schedule, l2_regularization_weight=l2_reg_weight)\n",
    "    progress_printer = ProgressPrinter(tag='Training', num_epochs=num_epochs)\n",
    "    trainer = Trainer(tl_model, (ce, pe), learner, progress_printer)\n",
    "\n",
    "    # Get minibatches of images and perform model training\n",
    "    print(\"Training transfer learning model for {0} epochs (epoch_size = {1}).\".format(num_epochs, epoch_size))\n",
    "    log_number_of_parameters(tl_model)\n",
    "    for epoch in range(num_epochs):       # loop over epochs\n",
    "        sample_count = 0\n",
    "        while sample_count < epoch_size:  # loop over minibatches in the epoch\n",
    "            data = minibatch_source.next_minibatch(min(mb_size, epoch_size-sample_count), input_map=input_map)\n",
    "            trainer.train_minibatch(data)                                    # update model with it\n",
    "            sample_count += trainer.previous_minibatch_sample_count          # count samples processed so far\n",
    "            if sample_count % (100 * mb_size) == 0:\n",
    "                print (\"Processed {0} samples\".format(sample_count))\n",
    "\n",
    "        trainer.summarize_training_progress()\n",
    "\n",
    "    return tl_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance Evaluation\n",
    "\n",
    "Evaluating the model is, in some sense, more painful than training it. You need to massage each image into the format that CNTK expects, which involves converting the pixel data into one big flattened array of floats in the right order. Once you've done that, you send it into the trained model and that spits out a value for each class. Running [Softmax](https://en.wikipedia.org/wiki/Softmax_function) over those values converts them into (roughly) a probability, and we pick the highest probability as our class (using `numpy.argmax`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluates a single image using the provided model\n",
    "def eval_single_image(loaded_model, image_path, image_width, image_height):\n",
    "    # load and format image (resize, RGB -> BGR, CHW -> HWC)\n",
    "    img = Image.open(image_path)\n",
    "    if image_path.endswith(\"png\"):\n",
    "        temp = Image.new(\"RGB\", img.size, (255, 255, 255))\n",
    "        temp.paste(img, img)\n",
    "        img = temp\n",
    "    resized = img.resize((image_width, image_height), Image.ANTIALIAS)\n",
    "    bgr_image = np.asarray(resized, dtype=np.float32)[..., [2, 1, 0]]\n",
    "    hwc_format = np.ascontiguousarray(np.rollaxis(bgr_image, 2))\n",
    "\n",
    "    ## Alternatively: if you want to use opencv-python\n",
    "    # cv_img = cv2.imread(image_path)\n",
    "    # resized = cv2.resize(cv_img, (image_width, image_height), interpolation=cv2.INTER_NEAREST)\n",
    "    # bgr_image = np.asarray(resized, dtype=np.float32)\n",
    "    # hwc_format = np.ascontiguousarray(np.rollaxis(bgr_image, 2))\n",
    "\n",
    "    # compute model output\n",
    "    arguments = {loaded_model.arguments[0]: [hwc_format]}\n",
    "    output = loaded_model.eval(arguments)\n",
    "\n",
    "    # return softmax probabilities\n",
    "    sm = softmax(output[0])\n",
    "    return sm.eval()\n",
    "\n",
    "# Evaluates an image set using the provided model\n",
    "def eval_test_images(loaded_model, output_file, test_map_file, image_width, image_height, max_images=-1, column_offset=0):\n",
    "    num_images = sum(1 for line in open(test_map_file))\n",
    "    if max_images > 0:\n",
    "        num_images = min(num_images, max_images)\n",
    "    print(\"Evaluating model output node '{0}' for {1} images.\".format(new_output_node_name, num_images))\n",
    "\n",
    "    pred_count = 0\n",
    "    correct_count = 0\n",
    "    np.seterr(over='raise')\n",
    "    with open(output_file, 'wb') as results_file:\n",
    "        with open(test_map_file, \"r\") as input_file:\n",
    "            for line in input_file:\n",
    "                tokens = line.rstrip().split('\\t')\n",
    "                img_file = tokens[0 + column_offset]\n",
    "                probs = eval_single_image(loaded_model, img_file, image_width, image_height)\n",
    "\n",
    "                pred_count += 1\n",
    "                true_label = int(tokens[1 + column_offset])\n",
    "                predicted_label = np.argmax(probs)\n",
    "                if predicted_label == true_label:\n",
    "                    correct_count += 1\n",
    "\n",
    "                np.savetxt(results_file, probs[np.newaxis], fmt=\"%.3f\")\n",
    "                if pred_count % 100 == 0:\n",
    "                    print(\"Processed {0} samples ({1} correct)\".format(pred_count, (float(correct_count) / pred_count)))\n",
    "                if pred_count >= num_images:\n",
    "                    break\n",
    "\n",
    "    print (\"{0} out of {1} predictions were correct {2}.\".format(correct_count, pred_count, (float(correct_count) / pred_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting It All Together\n",
    "\n",
    "Now that we can train and evaluate our model, let's put it all together into a final run, where we train our model for `max_epochs` epochs and evaluate the results on `_test_map_file`'s images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training transfer learning model for 20 epochs (epoch_size = 532).\n",
      "Training 15898178 parameters in 68 parameter tensors.\n",
      "Learning rate per minibatch: 0.2\n",
      "Momentum per minibatch: 0.9\n",
      "Finished Epoch[1 of 20]: [Training] loss = 0.691645 * 532, metric = 12.03% * 532 14.792s ( 36.0 samples/s);\n",
      "Finished Epoch[2 of 20]: [Training] loss = 0.248316 * 532, metric = 3.01% * 532 7.765s ( 68.5 samples/s);\n",
      "Finished Epoch[3 of 20]: [Training] loss = 0.720047 * 532, metric = 11.65% * 532 7.596s ( 70.0 samples/s);\n",
      "Finished Epoch[4 of 20]: [Training] loss = 0.782503 * 532, metric = 12.78% * 532 7.738s ( 68.8 samples/s);\n",
      "Finished Epoch[5 of 20]: [Training] loss = 0.214429 * 532, metric = 9.02% * 532 7.631s ( 69.7 samples/s);\n",
      "Finished Epoch[6 of 20]: [Training] loss = 0.133607 * 532, metric = 5.08% * 532 7.893s ( 67.4 samples/s);\n",
      "Finished Epoch[7 of 20]: [Training] loss = 0.128591 * 532, metric = 4.51% * 532 7.792s ( 68.3 samples/s);\n",
      "Finished Epoch[8 of 20]: [Training] loss = 0.087163 * 532, metric = 1.88% * 532 8.012s ( 66.4 samples/s);\n",
      "Finished Epoch[9 of 20]: [Training] loss = 0.044589 * 532, metric = 0.94% * 532 7.341s ( 72.5 samples/s);\n",
      "Finished Epoch[10 of 20]: [Training] loss = 0.074556 * 532, metric = 2.26% * 532 7.958s ( 66.9 samples/s);\n",
      "Learning rate per minibatch: 0.1\n",
      "Finished Epoch[11 of 20]: [Training] loss = 0.039567 * 532, metric = 1.32% * 532 7.602s ( 70.0 samples/s);\n",
      "Finished Epoch[12 of 20]: [Training] loss = 0.055295 * 532, metric = 1.69% * 532 7.798s ( 68.2 samples/s);\n",
      "Finished Epoch[13 of 20]: [Training] loss = 0.028482 * 532, metric = 0.56% * 532 8.097s ( 65.7 samples/s);\n",
      "Finished Epoch[14 of 20]: [Training] loss = 0.018723 * 532, metric = 1.13% * 532 7.776s ( 68.4 samples/s);\n",
      "Finished Epoch[15 of 20]: [Training] loss = 0.026028 * 532, metric = 0.94% * 532 8.196s ( 64.9 samples/s);\n",
      "Finished Epoch[16 of 20]: [Training] loss = 0.006844 * 532, metric = 0.00% * 532 7.741s ( 68.7 samples/s);\n",
      "Finished Epoch[17 of 20]: [Training] loss = 0.006446 * 532, metric = 0.00% * 532 7.953s ( 66.9 samples/s);\n",
      "Finished Epoch[18 of 20]: [Training] loss = 0.006471 * 532, metric = 0.19% * 532 7.669s ( 69.4 samples/s);\n",
      "Finished Epoch[19 of 20]: [Training] loss = 0.001304 * 532, metric = 0.00% * 532 7.945s ( 67.0 samples/s);\n",
      "Finished Epoch[20 of 20]: [Training] loss = 0.015165 * 532, metric = 0.56% * 532 7.736s ( 68.8 samples/s);\n",
      "Stored trained model at C:\\dev\\git_ws\\msready2017\\Output\\TransferLearning.model\n",
      "Evaluating model output node 'prediction' for 229 images.\n",
      "Processed 100 samples (0.94 correct)\n",
      "Processed 200 samples (0.91 correct)\n",
      "207 out of 229 predictions were correct 0.9039301310043668.\n",
      "Done. Wrote output to C:\\dev\\git_ws\\msready2017\\Output\\predOutput.txt\n"
     ]
    }
   ],
   "source": [
    "try_set_default_device(gpu(0))\n",
    "# check for model and data existence\n",
    "if not (os.path.exists(_base_model_file) and os.path.exists(_train_map_file) and os.path.exists(_test_map_file)):\n",
    "    print(\"Please run 'python download_model.py' and 'img_downloader.py' first to get the required data and model.\")\n",
    "    exit(0)\n",
    "\n",
    "# Train only if no model exists yet\n",
    "if os.path.exists(tl_model_file):\n",
    "    print(\"Loading existing model from %s\" % tl_model_file)\n",
    "    trained_model = load_model(tl_model_file)\n",
    "else:\n",
    "    trained_model = train_model(_base_model_file, _feature_node_name, _last_hidden_node_name,\n",
    "                                _image_width, _image_height, _num_channels, _num_classes, _train_map_file, max_epochs)\n",
    "    trained_model.save(tl_model_file)\n",
    "    print(\"Stored trained model at %s\" % tl_model_file)\n",
    "\n",
    "# Evaluate the test set\n",
    "eval_test_images(trained_model, output_file, _test_map_file, _image_width, _image_height)\n",
    "\n",
    "print(\"Done. Wrote output to %s\" % output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
